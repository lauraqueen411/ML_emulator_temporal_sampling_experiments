{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR 1: PROJ: proj_create_from_database: Open of /nesi/project/niwa00018/queenle/ml_env_v2/share/proj failed\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import glob\n",
    "import os\n",
    "from scipy.stats import binned_statistic, binned_statistic_dd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_dir = '/nesi/project/niwa00018/queenle/ML_emulator_temporal_sampling_experiments/plotting/compute_metrics/results/histogram_counts'\n",
    "plot_dir = '/nesi/project/niwa00018/queenle/ML_emulator_temporal_sampling_experiments/plotting/plots/histograms'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lhd_db(h1, h2, eps=1e-12):\n",
    "    h1 = np.asarray(h1)\n",
    "    h2 = np.asarray(h2)\n",
    "    assert h1.shape == h2.shape, \"Histograms must have the same shape\"\n",
    "    \n",
    "    mask = (h1 >= 10) & (h2 >= 10)\n",
    "    h1 = h1[mask]\n",
    "    h2 = h2[mask]\n",
    "\n",
    "    log_diff_dB = 10 * (np.log10(h1) - np.log10(h2))\n",
    "    lhd_db = np.sqrt(np.mean(log_diff_dB ** 2))\n",
    "    \n",
    "    return lhd_db\n",
    "\n",
    "def get_lhd(h1, h2):\n",
    "    # Convert to arrays in case they're lists\n",
    "    h1 = np.asarray(h1)\n",
    "    h2 = np.asarray(h2)\n",
    "    \n",
    "    assert h1.shape == h2.shape, \"Histograms must have the same shape\"\n",
    "    \n",
    "    mask = (h1 >= 10) & (h2 >= 10)\n",
    "    h1 = h1[mask]\n",
    "    h2 = h2[mask]\n",
    "    \n",
    "    return np.sum(np.abs(np.log1p(h1) - np.log1p(h2)))\n",
    "\n",
    "def write_to_dict(result_dict,period,epoch,gcm,ml_type,framework,n,lhd_db):\n",
    "    \n",
    "    result_dict['period'].append(period)\n",
    "    result_dict['epoch'].append(epoch)\n",
    "    result_dict['GCM'].append(gcm)\n",
    "    result_dict['ml_type'].append(ml_type)\n",
    "    result_dict['framework'].append(framework)\n",
    "    result_dict['sample_n'].append(n)\n",
    "    result_dict['lhd_db'].append(lhd_db)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Plot histograms \n",
    "'''\n",
    "\n",
    "for period in [('1985','2004')]:#,('2080','2099')]:\n",
    "    \n",
    "    start,end = period\n",
    "    \n",
    "    for gcm in ['EC-Earth3','NorESM2-MM']:\n",
    "\n",
    "        for epoch in ['220','225','230']:\n",
    "\n",
    "            if os.path.exists(f'/nesi/project/niwa00018/queenle/ML_emulator_temporal_sampling_experiments/plotting/histograms/{gcm}_epoch_{epoch}_{start}-{end}.png'):\n",
    "                print('file exists, skipping')\n",
    "                continue\n",
    "\n",
    "            fig,axs = plt.subplots(6,2,figsize=(12,12),sharex=True,sharey=True,layout='constrained')\n",
    "\n",
    "            for j,framework in enumerate(['perfect','imperfect']):\n",
    "\n",
    "                gan_df = pd.read_csv(f'{counts_dir}/{gcm}_GAN_{framework}_epoch_{epoch}_{start}-{end}_histogram_counts.csv').drop('Unnamed: 0',axis=1)\n",
    "                unet_df = pd.read_csv(f'{counts_dir}/{gcm}_unet_{framework}_epoch_{epoch}_{start}-{end}_histogram_counts.csv').drop('Unnamed: 0',axis=1)\n",
    "\n",
    "                for i,n in enumerate([5,10,20,60,100,140]):\n",
    "\n",
    "                    bins = gan_df['bin_left'].values.tolist() + [gan_df['bin_right'].values[-1]]\n",
    "\n",
    "                    gan_counts = gan_df[str(n)]\n",
    "                    unet_counts = unet_df[str(n)]\n",
    "                    ccam_counts = gan_df['CCAM']\n",
    "\n",
    "                    axs[i][j].stairs(gan_counts,bins,color='blue',label=f'GAN')\n",
    "                    axs[i][j].stairs(unet_counts,bins,color='green',label=f'unet')\n",
    "                    axs[i][j].stairs(ccam_counts,bins,color='red',label=f'CCAM')\n",
    "\n",
    "                    axs[i][j].set_yscale('log')\n",
    "\n",
    "                    axs[i][j].text(0.5,0.8,f'{n} Years', transform=axs[i][j].transAxes,ha='center', va='bottom', fontsize=20)\n",
    "\n",
    "                    axs[i][j].set_yscale('log')\n",
    "                    axs[i][j].tick_params(axis='y', labelsize=16)\n",
    "                    axs[i][j].tick_params(axis='x', labelsize=16)\n",
    "\n",
    "                    if i == 5:\n",
    "                        axs[i][j].set_xlabel('pr (mm/day)',fontsize=20)\n",
    "\n",
    "            axs[0][1].legend()\n",
    "            axs[0][0].set_title('PERFECT',fontsize=22)\n",
    "            axs[0][1].set_title('IMPERFECT',fontsize=22)\n",
    "\n",
    "            plt.savefig(f'{plot_dir}/{gcm}_epoch_{epoch}_{start}-{end}.png',dpi=300)\n",
    "            plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter_env",
   "language": "python",
   "name": "nellys_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
